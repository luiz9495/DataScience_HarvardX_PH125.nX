---
title: "Data Science: Inference and Modeling - HarvardX: PH125.4x"
output: html_notebook
---

# Section 3: Confidence Intervals and p-Values

## 3.1 Overview

After completing Section 3, you will be able to:

* Calculate confidence intervals of difference sizes around an estimate.
* Understand that a confidence interval is a random interval with the given probability of falling on top of the parameter.
* Explain the concept of "power" as it relates to inference.
* Understand the relationship between p-values and confidence intervals and explain why reporting confidence intervals is often preferable.

```{r}
library(tidyverse)
```

## 3.2 Confidence Intervals and p-Values

### 3.2.1 Confidence Intervals

**Key points**

* We can use statistical theory to compute the probability that a given interval contains the true parameter $p$ .
* 95% confidence intervals are intervals constructed to have a 95% chance of including $p$ . The margin of error is approximately a 95% confidence interval.
* The start and end of these confidence intervals are random variables.
* To calculate any size confidence interval, we need to calculate the value $z$ for which $Pr(-z \le Z \le z)$ equals the desired confidence. For example, a 99% confidence interval requires calculating $z$ for $Pr(-z \le Z \le z) = 0.99$.
* For a confidence interval of size $q$, we solve for $x = 1 - \frac{1-q}{2}$.
* To determine a 95% confidence interval, use *z <- qnorm(0.975)*. This value is slightly smaller than 2 times the standard error.

**Code: geom_smooth confidence interval example**

The shaded area around the curve is related to the concept of confidence intervals.
```{r}
data("nhtemp")
data.frame(year = as.numeric(time(nhtemp)), temperature = as.numeric(nhtemp)) %>%
    ggplot(aes(year, temperature)) +
    geom_point() +
    geom_smooth() +
    ggtitle("Average Yearly Temperatures in New Haven")
```

**Code: Monte Carlo simulation of confidence intervals**

Note that to compute the exact 95% confidence interval, we would use qnorm(.975) * $\hat{SE}$ instead of $2 * $\hat{SE}$.
```{r}
p <- 0.45
N <- 1000
X <- sample(c(0,1), size = N, replace = TRUE, prob = c(1-p, p))    # generate N observations
X_hat <- mean(X)    # calculate X_hat
SE_hat <- sqrt(X_hat*(1-X_hat)/N)    # calculate SE_hat, SE of the mean of N observations
c(X_hat - 2*SE_hat, X_hat + 2*SE_hat)    # build interval of 2*SE above and below mean
```

**Code: Solving for $z$  with qnorm**
```{r}
z <- qnorm(0.995)    # calculate z to solve for 99% confidence interval
pnorm(qnorm(0.995))    # demonstrating that qnorm gives the z value for a given probability
pnorm(1-qnorm(0.995))    # demonstrating symmetry of 1-qnorm
pnorm(z) - pnorm(-z)    # demonstrating that this z value gives correct probability for interval
```

### 3.2.2 A Monte Carlo Simulation for Confidence Intervals

**Key points**

* We can run a Monte Carlo simulation to confirm that a 95% confidence interval contains the true value of $p$ 95% of the time.
* A plot of confidence intervals from this simulation demonstrates that most intervals include $p$, but roughly 5% of intervals miss the true value of $p$.

**Code: Monte Carlo simulation**

Note that to compute the exact 95% confidence interval, we would use qnorm(.975) * SE_hat instead of 2 * SE_hat.

```{r}
B <- 10000
inside <- replicate(B, {
    X <- sample(c(0,1), size = N, replace = TRUE, prob = c(1-p, p))
    X_hat <- mean(X)
    SE_hat <- sqrt(X_hat*(1-X_hat)/N)
    between(p, X_hat - 2*SE_hat, X_hat + 2*SE_hat)    # TRUE if p in confidence interval
})
mean(inside)
```

### 3.2.3 The Correct Language

**Key points**

* The 95% confidence intervals are random, but $p$ is not random.
* 95% refers to the probability that the random interval falls on top of $p$.
* It is technically incorrect to state that $p$ has a 95% chance of being in between two values because that implies $p$ is random.

### 3.2.4 Power

**Key points**

* If we are trying to predict the result of an election, then a confidence interval that includes a spread of 0 (a tie) is not helpful.
* A confidence interval that includes a spread of 0 does not imply a close election, it means the sample size is too small.
* Power is the probability of detecting an effect when there is a true effect to find. Power increases as sample size increases, because larger sample size means smaller standard error.

**Code: Confidence interval for the spread with sample size of 25**

Note that to compute the exact 95% confidence interval, we would use c(-qnorm(.975), qnorm(.975)) instead of 1.96.

```{r}
N <- 25
X_hat <- 0.48
spread <- (2*X_hat - 1)
sd_spread <- 2 * sqrt(X_hat*(1-X_hat)/sqrt(N))
spread + c(-qnorm(.975), qnorm(.975)) * sd_spread
```

### 3.2.5 p-Values

**Key points**

* The null hypothesis is the hypothesis that there is no effect. In this case, the null hypothesis is that the spread is 0, or $p =0.5$.
* The p-value is the probability of detecting an effect of a certain size or larger when the null hypothesis is true.
* We can convert the probability of seeing an observed value under the null hypothesis into a standard normal random variable. We compute the value of  ð‘§  that corresponds to the observed result, and then use that  ð‘§  to compute the p-value.
* If a 95% confidence interval does not include our observed value, then the p-value must be smaller than 0.05.
* It is preferable to report confidence intervals instead of p-values, as confidence intervals give information about the size of the estimate and p-values do not.

**Code: Computing a p-value for observed spread of 0.02**
```{r}
N <- 100    # sample size
z <- sqrt(N) * 0.02/0.5    # spread of 0.02
1 - (pnorm(z) - pnorm(-z))
```


### 3.2.6 Assessment

#### Exercise 1. Confidence interval for p
For the following exercises, we will use actual poll data from the 2016 election. The exercises will contain pre-loaded data from the dslabs package.

```{r}
library(dslabs)
data("polls_us_election_2016")
```

We will use all the national polls that ended within a few weeks before the election.  
Assume there are only two candidates and construct a 95% confidence interval for the election night proportion p.

**Instructions**

* Use filter to subset the data set for the poll data you want. Include polls that ended on or after October 31, 2016 (enddate). Only include polls that took place in the United States. Call this filtered object polls.
* Use nrow to make sure you created a filtered object polls that contains the correct number of rows.
* Extract the sample size N from the first poll in your subset object polls.
* Convert the percentage of Clinton voters (rawpoll_clinton) from the first poll in polls to a proportion, X_hat. Print this value to the console.
* Find the standard error of X_hat given N. Print this result to the console.
* Calculate the 95% confidence interval of this estimate using the qnorm function.
* Save the lower and upper confidence intervals as an object called ci. Save the lower confidence interval first.

**Code**
```{r}
# Load the data
data(polls_us_election_2016)
#str(polls_us_election_2016)

# Generate an object `polls` that contains data filtered for polls that ended on or after October 31, 2016 in the United States
polls <- polls_us_election_2016 %>%
    filter(enddate >= "2016-10-31", state=='U.S.')

# How many rows does `polls` contain? Print this value to the console.
nrow(polls)

# Assign the sample size of the first poll in `polls` to a variable called `N`. Print this value to the console.
N <- polls[1,]$samplesize
N

# For the first poll in `polls`, assign the estimated percentage of Clinton voters to a variable called `X_hat`. Print this value to the console.
X_hat <- polls[1,]$rawpoll_clinton/100
X_hat

# Calculate the standard error of `X_hat` and save it to a variable called `se_hat`. Print this value to the console.
se_hat <- sqrt(X_hat*(1-X_hat)/N)
se_hat

# Use `qnorm` to calculate the 95% confidence interval for the proportion of Clinton voters. Save the lower and then the upper confidence interval to a variable called `ci`.
ci <- X_hat + c(-qnorm(.975), qnorm(.975)) * se_hat

```

#### Exercise 2. Pollster results for p
Create a new object called pollster_results that contains the pollster's name, the end date of the poll, the proportion of voters who declared a vote for Clinton, the standard error of this estimate, and the lower and upper bounds of the confidence interval for the estimate.

**Instructions**

* Use the mutate function to define four new columns: X_hat, se_hat, lower, and upper. Temporarily add these columns to the polls object that has already been loaded for you.
* In the X_hat column, convert the raw poll results for Clinton to a proportion.
* In the se_hat column, calculate the standard error of X_hat for each poll using the sqrt function.
* In the lower column, calculate the lower bound of the 95% confidence interval using the qnorm function.
* In the upper column, calculate the upper bound of the 95% confidence interval using the qnorm function.
* Use the select function to select the columns from polls to save to the new object pollster_results.

**Code**
```{r}
# The `polls` object that filtered all the data by date and nation has already been loaded. Examine it using the `head` function.
head(polls)

# Create a new object called `pollster_results` that contains columns for pollster name, end date, X_hat, se_hat, lower confidence interval, and upper confidence interval for each poll.
pollster_results <- polls %>%
    mutate(X_hat = rawpoll_clinton/100, 
           se_hat = sqrt(X_hat*(1-X_hat)/samplesize),
           lower = X_hat - qnorm(.975) * se_hat,
           upper = X_hat + qnorm(.975) * se_hat) %>%
    select(pollster, enddate, X_hat, se_hat, lower, upper)
pollster_results
```

#### Exercise 3. Comparing to actual results - p
The final tally for the popular vote was Clinton 48.2% and Trump 46.1%. Add a column called hit to pollster_results that states if the confidence interval included the true proportion p=0.482 or not. What proportion of confidence intervals included p?

**Instructions**

* Use the mutate function to define a new variable called 'hit'.
* Use logical expressions to determine if each values in lower and upper span the actual proportion.
* Use the mean function to determine the average value in hit and summarize the results using summarize.
* Save the result as an object called avg_hit.

**Code**
```{r}
# The `pollster_results` object has already been loaded. Examine it using the `head` function.
head(pollster_results)

# Add a logical variable called `hit` that indicates whether the actual value exists within the confidence interval of each poll. Summarize the average `hit` result to determine the proportion of polls with confidence intervals include the actual value. Save the result as an object called `avg_hit`.
avg_hit <- pollster_results %>%
    mutate(hit=(0.482>=lower & 0.482<=upper)) %>%
    summarize(mean(hit))
avg_hit
```

#### Exercise 5. Confidence interval for d
A much smaller proportion of the polls than expected produce confidence intervals containing p. Notice that most polls that fail to include p are underestimating. The rationale for this is that undecided voters historically divide evenly between the two main candidates on election day.  
In this case, it is more informative to estimate the spread or the difference between the proportion of two candidates d, or 0.482âˆ’0.461=0.021 for this election.  
Assume that there are only two parties and that d=2pâˆ’1. Construct a 95% confidence interval for difference in proportions on election night.

**Instructions**

* Use the mutate function to define a new variable called 'd_hat' in polls. The new variable subtract the proportion of Trump voters from the proportion of Clinton voters.
* Extract the sample size N from the first poll in your subset object polls.
* Extract the difference in proportions of voters d_hat from the first poll in your subset object polls.
* Use the formula above to calculate p from d_hat. Assign p to the variable X_hat.
* Find the standard error of the spread given N.
* Calculate the 95% confidence interval of this estimate of the difference in proportions, d_hat, using the qnorm function.
* Save the lower and upper confidence intervals as an object called ci. Save the lower confidence interval first.

**Code**
```{r}
# Add a statement to this line of code that will add a new column named `d_hat` to `polls`. The new column should contain the difference in the proportion of voters.
polls <- polls_us_election_2016 %>% 
    filter(enddate >= "2016-10-31" & state == "U.S.") %>%
    mutate(d_hat= 1/100*(rawpoll_clinton - rawpoll_trump))

# Assign the sample size of the first poll in `polls` to a variable called `N`. Print this value to the console.
N <- polls[1,]$samplesize
N

# For the difference `d_hat` of the first poll in `polls` to a variable called `d_hat`. Print this value to the console.
d_hat <- polls[1,]$d_hat

# Assign proportion of votes for Clinton to the variable `X_hat`.
X_hat <- (d_hat+1)/2
    
# Calculate the standard error of the spread and save it to a variable called `se_hat`. Print this value to the console.
se_hat <- 2 * sqrt(X_hat*(1-X_hat)/N)
se_hat

# Use `qnorm` to calculate the 95% confidence interval for the difference in the proportions of voters. Save the lower and then the upper confidence interval to a variable called `ci`.
ci <- d_hat + c(-qnorm(0.975), qnorm(0.975)) * se_hat
```

#### Exercise 6. Pollster results for d
Create a new object called pollster_results that contains the pollster's name, the end date of the poll, the difference in the proportion of voters who declared a vote either, and the lower and upper bounds of the confidence interval for the estimate.

**Instructions**

* Use the mutate function to define four new columns: 'X_hat', 'se_hat', 'lower', and 'upper'. Temporarily add these columns to the polls object that has already been loaded for you.
* In the X_hat column, calculate the proportion of voters for Clinton using d_hat.
* In the se_hat column, calculate the standard error of the spread for each poll using the sqrt function.
* In the lower column, calculate the lower bound of the 95% confidence interval using the qnorm function.
* In the upper column, calculate the upper bound of the 95% confidence interval using the qnorm function.
* Use the select function to select the pollster, enddate, d_hat, lower, upper columns from polls to save to the new object pollster_results

**Code**
```{r}
# The subset `polls` data with 'd_hat' already calculated has been loaded. Examine it using the `head` function.
head(polls)

# Create a new object called `pollster_results` that contains columns for pollster name, end date, d_hat, lower confidence interval of d_hat, and upper confidence interval of d_hat for each poll.
pollster_results <- polls %>%
    mutate(X_hat = (d_hat+1)/2, 
           se_hat = 2 * sqrt(X_hat*(1-X_hat)/samplesize),
           lower = d_hat - qnorm(.975) * se_hat,
           upper = d_hat + qnorm(.975) * se_hat) %>%
    select(pollster, enddate, d_hat, lower, upper)
pollster_results

```

#### Exercise 7. Comparing to actual results - d
What proportion of confidence intervals for the difference between the proportion of voters included d, the actual difference in election day?

**Instructions**

* Use the mutate function to define a new variable within pollster_results called hit.
* Use logical expressions to determine if each values in lower and upper span the actual difference in proportions of voters.
* Use the mean function to determine the average value in hit and summarize the results using summarize.
* Save the result as an object called avg_hit.

**Code**
```{r}
# The `pollster_results` object has already been loaded. Examine it using the `head` function.
head(pollster_results)

# Add a logical variable called `hit` that indicates whether the actual value (0.021) exists within the confidence interval of each poll. Summarize the average `hit` result to determine the proportion of polls with confidence intervals include the actual value. Save the result as an object called `avg_hit`.
avg_hit <- pollster_results %>%
    mutate(hit=0.021>=lower & 0.021<=upper) %>%
    summarize(mean(hit))
avg_hit
```

#### Exercise 8. Comparing to actual results by pollster
Although the proportion of confidence intervals that include the actual difference between the proportion of voters increases substantially, it is still lower that 0.95. In the next chapter, we learn the reason for this.

To motivate our next exercises, calculate the difference between each poll's estimate dÂ¯ and the actual d=0.021. Stratify this difference, or error, by pollster in a plot.

**Instructions**

* Define a new variable errors that contains the difference between the estimated difference between the proportion of voters and the actual difference on election day, 0.021.
* To create the plot of errors by pollster, add a layer with the function geom_point. The aesthetic mappings require a definition of the x-axis and y-axis variables. So the code looks like the example below, but you fill in the variables for x and y.
* The last line of the example code adjusts the x-axis labels so that they are easier to read.  

> data %>% ggplot(aes(x = , y = )) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

**Code**
```{r}
# The `polls` object has already been loaded. Examine it using the `head` function.
head(polls)

# Add variable called `error` to the object `polls` that contains the difference between d_hat and the actual difference on election day. Then make a plot of the error stratified by pollster.
polls %>%
    mutate(error=d_hat-0.021) %>%
    ggplot(aes(x = pollster, y = error)) +
    geom_point() +
    theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

#### Exercise 9. Comparing to actual results by pollster - multiple polls
Remake the plot you made for the previous exercise, but only for pollsters that took five or more polls.

You can use dplyr tools group_by and n to group data by a variable of interest and then count the number of observations in the groups. The function filter filters data piped into it by your specified condition.

For example:
> data %>% group_by(variable_for_grouping)  
    %>% filter(n() >= 5)

**Instructions**

* Define a new variable errors that contains the difference between the estimated difference between the proportion of voters and the actual difference on election day, 0.021.
* Group the data by pollster using the group_by function.
* Filter the data by pollsters with 5 or more polls.
* Use ggplot to create the plot of errors by pollster.
* Add a layer with the function geom_point.

**Code**
```{r}
# The `polls` object has already been loaded. Examine it using the `head` function.
head(polls)

# Add variable called `error` to the object `polls` that contains the difference between d_hat and the actual difference on election day. Then make a plot of the error stratified by pollster, but only for pollsters who took 5 or more polls.
polls %>%
    group_by(pollster) %>% 
    filter(n() >= 5)  %>% 
    mutate(error=d_hat-0.021) %>%
    ggplot(aes(x = pollster, y = error)) +
    geom_point() +
    theme(axis.text.x = element_text(angle = 90, hjust = 1))
```


